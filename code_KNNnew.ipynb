{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9e6e841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1066162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69c26990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "if tf.test.gpu_device_name(): \n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6aace323",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, ZeroPadding3D , BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf7880b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46ed9eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "img_height = 200\n",
    "img_width = 200 \n",
    "NUM_CLASSES = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fda5c59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "data_dir = r\"C:\\Users\\kuric\\Desktop\\AI Camp\\Code\\Project_back\\Data_aug_Unclean\"\n",
    "data_dir = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "023f6b86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "485\n"
     ]
    }
   ],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "756e41fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9351 files belonging to 6 classes.\n",
      "Using 2806 files for training.\n",
      "Found 9351 files belonging to 6 classes.\n",
      "Using 2805 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.7,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.3,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb52293b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bungarus', 'Calloselasma', 'Daboia_russelii', 'Naja', 'Ophiophagus', 'Trimeresurus']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0621481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for images, labels in train_ds.take(1):\n",
    "#     for i in range(6):\n",
    "#         ax = plt.subplot(4, 4, i + 1)\n",
    "#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#         plt.title(class_names[labels[i]])\n",
    "#         plt.axis(\"off\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ea0c24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_name = \"KNN\"\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d30b8eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################################################\n",
    "nb_epochs=10\n",
    "################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f6e9f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Train  with backup h5 every epoch. #####################\n",
    "\n",
    "\n",
    "# checkpoint_path = r\"./ModelSaving/{epoch:04d}.h5\"\n",
    "# checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     checkpoint_path, verbose=1, save_weights_only=False,\n",
    "#     # Save weights, every epoch.\n",
    "#     save_freq='epoch'\n",
    "# )\n",
    "# resnet_model.save(checkpoint_path.format(epoch=0))\n",
    "# vg = validation_generator\n",
    "# history = resnet_model.fit( train_generator, validation_data=vg ,epochs=nb_epochs, callbacks = [cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd2e5ff7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnb_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "history = model.fit( train_ds, val_ds )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e595241",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(nb_epochs)\n",
    "\n",
    "print(\"Model = \"+model_name)\n",
    "print(\"Epochs = {}\".format(nb_epochs))\n",
    "print(\"Image Size = {}\".format(img_width))\n",
    "print(\"Batch = {}\".format(batch_size))\n",
    "print(\"learningRate = {}\".format(learningRate))\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "#####  use this  to save train graph as png #####################\n",
    "from datetime import datetime\n",
    "dt = datetime.now()\n",
    "ts = datetime.timestamp(dt)\n",
    "date_time = datetime.fromtimestamp(ts)\n",
    "str_date_time = date_time.strftime(\"%d-%m-%Y_%H-%M\")\n",
    "graph_path = r'./experimentData/graph'\n",
    "if( not (os.path.exists(graph_path)) ) :\n",
    "    os.mkdir(graph_path)\n",
    "plt.savefig(graph_path+'/'+str_date_time+\".png\")  \n",
    "#####  use this  to save train graph as png #####################\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "graph_path = graph_path+'/'+str_date_time+\".png\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a45f5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r\"./ModelSaving/FinalModel_\"+model_name+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bca4936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "dt = datetime.now()\n",
    "ts = datetime.timestamp(dt)\n",
    "date_time = datetime.fromtimestamp(ts)\n",
    "str_date_time = date_time.strftime(\"%d/%m/%Y, %H:%M\")\n",
    "\n",
    "\n",
    "\n",
    "############################# List that var should be defined   \n",
    "############################# รายชื่อตัวแปร ที่ควรสร้าง และใส่ค่า \n",
    "varList = {\"model_name\",   ### name of model\n",
    "           \"nb_epochs\",     ### number of epochs\n",
    "           \"batch_size\",    ###  batch size\n",
    "           \"learningRate\",  ### learning rate\n",
    "           \"accuracy\",       ###  accuracy of model\n",
    "           \"val_accuracy\",  ### val_accuracy  of model\n",
    "           \"loss\",          ### loss  of model\n",
    "           \"val_loss\",      ### val_loss  of model\n",
    "           \"loss_function\", ### lossfunction name    Must be str\n",
    "           \"graph_path\",    ###  path to graph dir\n",
    "           \"exp_dataset\",  ###  explain about dataset\n",
    "           \"other_comment\"}  ###  option  for comment\n",
    "#############################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pathDir = r'./experimentData'\n",
    "path = r'./experimentData/Experiment.csv'\n",
    "\n",
    "ExpDict = {\n",
    "            'Date': [],\n",
    "            'ModelName': [],\n",
    "            'Epochs' : [],\n",
    "            'ImageSize' : [],\n",
    "            'Batch': [],\n",
    "            'LearningRate' : [],\n",
    "            'Accuracy' : [],\n",
    "            'valAccuracy': [],\n",
    "            'loss' : [],\n",
    "            'valLoss' : [],\n",
    "            'lossFunction' : [],\n",
    "            'GraphPath' : [],\n",
    "            'ExpDataSet' : [],\n",
    "            'otherComment' : []\n",
    "             }\n",
    "\n",
    "if(not (os.path.exists(path))) :\n",
    "    dt = pd.DataFrame(ExpDict)\n",
    "    if( not (os.path.exists(pathDir)) ) :\n",
    "            os.mkdir(pathDir)\n",
    "    dt.to_csv(path,na_rep='',float_format='%.2f',index=False)\n",
    "\n",
    "expExel = pd.read_csv(path)\n",
    "\n",
    "for var in varList :\n",
    "    if not(var in globals()):\n",
    "        exec(var + \" = ''\")\n",
    "\n",
    "        \n",
    "ExpDict[\"Date\"] = str_date_time\n",
    "ExpDict[\"ModelName\"] = model_name\n",
    "ExpDict[\"Epochs\"] = str(nb_epochs)\n",
    "if (\"img_height\" in globals()) and  (\"img_width\" in globals()):\n",
    "    ExpDict[\"ImageSize\"] = str(\"HeightWidth = {}*{}\".format(img_height,img_width))\n",
    "elif (\"img_size\" in globals()):\n",
    "    ExpDict[\"ImageSize\"] = str(\"ImageSize = {}\".format(img_size))\n",
    "else :\n",
    "    ExpDict[\"ImageSize\"] = \"\"\n",
    "ExpDict[\"Batch\"] = str(batch_size)\n",
    "ExpDict[\"LearningRate\"] = str(learningRate)\n",
    "ExpDict[\"Accuracy\"] = str(acc)\n",
    "ExpDict[\"valAccuracy\"] = str(val_acc)\n",
    "ExpDict[\"loss\"] = str(loss)\n",
    "ExpDict[\"valLoss\"] = str(val_loss)\n",
    "ExpDict[\"lossFunction\"] = loss_function\n",
    "ExpDict[\"GraphPath\"] = graph_path\n",
    "ExpDict[\"ExpDataSet\"] = exp_dataset\n",
    "ExpDict[\"otherComment\"] = other_comment\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf71803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  บันทึกทับลง exel\n",
    "expExel = expExel.append(ExpDict,ignore_index=True)\n",
    "expExel.to_csv(path,na_rep='',float_format='%.2f',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5538bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5033e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fbfc05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:scAI]",
   "language": "python",
   "name": "conda-env-scAI-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
